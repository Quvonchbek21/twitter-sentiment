{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6399671,"sourceType":"datasetVersion","datasetId":3689799}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.097404Z","iopub.execute_input":"2025-11-09T10:18:57.097803Z","iopub.status.idle":"2025-11-09T10:18:57.106538Z","shell.execute_reply.started":"2025-11-09T10:18:57.097770Z","shell.execute_reply":"2025-11-09T10:18:57.105573Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/twitter-sentiment-analysis/twitter_validation.csv\n/kaggle/input/twitter-sentiment-analysis/twitter_training.csv\n","output_type":"stream"}],"execution_count":293},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.108422Z","iopub.execute_input":"2025-11-09T10:18:57.108741Z","iopub.status.idle":"2025-11-09T10:18:57.124431Z","shell.execute_reply.started":"2025-11-09T10:18:57.108715Z","shell.execute_reply":"2025-11-09T10:18:57.123201Z"}},"outputs":[{"name":"stdout","text":"['twitter-sentiment-analysis']\n","output_type":"stream"}],"execution_count":294},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport re\n\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.125508Z","iopub.execute_input":"2025-11-09T10:18:57.125803Z","iopub.status.idle":"2025-11-09T10:18:57.146478Z","shell.execute_reply.started":"2025-11-09T10:18:57.125779Z","shell.execute_reply":"2025-11-09T10:18:57.145386Z"}},"outputs":[],"execution_count":295},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/twitter-sentiment-analysis/twitter_training.csv\",\n                 encoding='latin-1',\n                 names=['id','topic','sentiment','text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.147738Z","iopub.execute_input":"2025-11-09T10:18:57.148066Z","iopub.status.idle":"2025-11-09T10:18:57.356893Z","shell.execute_reply.started":"2025-11-09T10:18:57.148030Z","shell.execute_reply":"2025-11-09T10:18:57.355935Z"}},"outputs":[],"execution_count":296},{"cell_type":"code","source":"df = df[['text', 'sentiment']]\ndf = df[df['sentiment'].isin(['Positive', 'Negative'])]\ndf = df.sample(30000, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.359311Z","iopub.execute_input":"2025-11-09T10:18:57.360027Z","iopub.status.idle":"2025-11-09T10:18:57.387418Z","shell.execute_reply.started":"2025-11-09T10:18:57.359993Z","shell.execute_reply":"2025-11-09T10:18:57.386309Z"}},"outputs":[],"execution_count":297},{"cell_type":"code","source":"def clean_text(text):\n    import re\n    stop_words = {\n        'i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself',\n        'yourselves','he','him','his','himself','she','her','hers','herself','it','its','itself',\n        'they','them','their','theirs','themselves','what','which','who','whom','this','that',\n        'these','those','am','is','are','was','were','be','been','being','have','has','had',\n        'having','do','does','did','doing','a','an','the','and','but','if','or','because','as',\n        'until','while','of','at','by','for','with','about','against','between','into','through',\n        'during','before','after','above','below','to','from','up','down','in','out','on','off',\n        'over','under','again','further','then','once','here','there','when','where','why','how',\n        'all','any','both','each','few','more','most','other','some','such','no','nor','not',\n        'only','own','same','so','than','too','very','s','t','can','will','just','don','should',\n        'now'\n    }\n    \n    \n    text = re.sub(r\"http\\S+|@\\w+|[^a-zA-Z\\s]\", \" \", str(text))\n    text = text.lower()\n    words = [w for w in text.split() if w not in stop_words and len(w) > 1]\n    return \" \".join(words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.388650Z","iopub.execute_input":"2025-11-09T10:18:57.388975Z","iopub.status.idle":"2025-11-09T10:18:57.398702Z","shell.execute_reply.started":"2025-11-09T10:18:57.388941Z","shell.execute_reply":"2025-11-09T10:18:57.397609Z"}},"outputs":[],"execution_count":298},{"cell_type":"code","source":"df['clean_text'] = df['text'].fillna('').apply(clean_text)\ndf['sentiment'] = df['sentiment'].map({'Negative': 0, 'Positive': 1})\ndf = df[['clean_text', 'sentiment']]\n\nprint(df['sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.399899Z","iopub.execute_input":"2025-11-09T10:18:57.400219Z","iopub.status.idle":"2025-11-09T10:18:57.784376Z","shell.execute_reply.started":"2025-11-09T10:18:57.400183Z","shell.execute_reply":"2025-11-09T10:18:57.783249Z"}},"outputs":[{"name":"stdout","text":"sentiment\n0    15657\n1    14343\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":299},{"cell_type":"code","source":"def tokenize(text):\n    return text.split()\n\ncounter = Counter(word for text in df['clean_text'] for word in tokenize(text))\nmost_common = counter.most_common(10000)\nvocab = {word: i+2 for i, (word, _) in enumerate(most_common)}\nvocab['<pad>'] = 0\nvocab['unk'] = 1\n\ndef encode(text):\n    encoded = [vocab.get(word, vocab['unk']) for word in text.lower().split()]\n    vocab_size = len(vocab)\n    # tokenlar vocab chegarasidan chiqmasligi uchun\n    encoded = [min(tok, vocab_size - 1) for tok in encoded]\n    return torch.tensor(encoded, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.785442Z","iopub.execute_input":"2025-11-09T10:18:57.785719Z","iopub.status.idle":"2025-11-09T10:18:57.902842Z","shell.execute_reply.started":"2025-11-09T10:18:57.785690Z","shell.execute_reply":"2025-11-09T10:18:57.901933Z"}},"outputs":[],"execution_count":300},{"cell_type":"code","source":"class TwitterDataset(Dataset):\n    def __init__(self, df):\n        self.X = [encode(t) for t in df['clean_text']]\n\n        self.y = torch.tensor(df['sentiment'].values, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\nfrom torch.nn.utils.rnn import pad_sequence\n\ndef collate_fn(batch):\n    Xs, ys = zip(*batch)\n    Xs_padded = pad_sequence(Xs, batch_first=True, padding_value=0).long()\n    ys = torch.stack(ys).float()  # ðŸ”¹ Warning yoâ€˜q\n    return Xs_padded, ys\n\n\ntrain_loader = DataLoader(TwitterDataset(df), batch_size=64, shuffle=True, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:57.903766Z","iopub.execute_input":"2025-11-09T10:18:57.904060Z","iopub.status.idle":"2025-11-09T10:18:58.773666Z","shell.execute_reply.started":"2025-11-09T10:18:57.904027Z","shell.execute_reply":"2025-11-09T10:18:58.772805Z"}},"outputs":[],"execution_count":301},{"cell_type":"code","source":"class SentimentLSTM(nn.Module):\n    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128, num_layers=2, dropout=0.3):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n        self.fc = nn.Linear(hidden_dim, 1)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        _, (h, _) = self.lstm(x)\n        out = self.fc(h[-1])\n        return out  # sigmoid yoâ€˜q!\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SentimentLSTM(len(vocab)).to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:58.782393Z","iopub.execute_input":"2025-11-09T10:18:58.782759Z","iopub.status.idle":"2025-11-09T10:18:58.801531Z","shell.execute_reply.started":"2025-11-09T10:18:58.782733Z","shell.execute_reply":"2025-11-09T10:18:58.800535Z"}},"outputs":[],"execution_count":302},{"cell_type":"code","source":"for epoch in range(10):\n    model.train()\n    total_loss = 0\n    for X, y in train_loader:\n        X, y = X.to(device), y.to(device)\n\n        optimizer.zero_grad()\n        y_pred = model(X).squeeze(1)\n        loss = criterion(y_pred, y)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:18:58.802559Z","iopub.execute_input":"2025-11-09T10:18:58.802871Z","iopub.status.idle":"2025-11-09T10:22:56.088214Z","shell.execute_reply.started":"2025-11-09T10:18:58.802838Z","shell.execute_reply":"2025-11-09T10:22:56.087086Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.6349\nEpoch 2, Loss: 0.4694\nEpoch 3, Loss: 0.3639\nEpoch 4, Loss: 0.2901\nEpoch 5, Loss: 0.2498\nEpoch 6, Loss: 0.1985\nEpoch 7, Loss: 0.1732\nEpoch 8, Loss: 0.1416\nEpoch 9, Loss: 0.1279\nEpoch 10, Loss: 0.1245\n","output_type":"stream"}],"execution_count":303},{"cell_type":"code","source":"def predict(text):\n    model.eval()\n    with torch.no_grad():\n        tokens = [vocab.get(w, 1) for w in text.lower().split()]\n        X = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n        output = model(X)\n        prob = torch.sigmoid(output).item()\n        label = \"positive ðŸ˜€\" if prob >= 0.5 else \"negative ðŸ˜ž\"\n        print(f\"Probability: {prob:.2f}, Label: {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:22:56.089407Z","iopub.execute_input":"2025-11-09T10:22:56.089721Z","iopub.status.idle":"2025-11-09T10:22:56.096513Z","shell.execute_reply.started":"2025-11-09T10:22:56.089693Z","shell.execute_reply":"2025-11-09T10:22:56.095647Z"}},"outputs":[],"execution_count":304},{"cell_type":"code","source":"predict(\"i really love it\")\npredict(\"it is ok\")\npredict(\"it is wonderful\")\npredict(\"i do not like because it is awful\")\npredict(\"it is bad\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:22:56.099034Z","iopub.execute_input":"2025-11-09T10:22:56.099571Z","iopub.status.idle":"2025-11-09T10:22:56.128821Z","shell.execute_reply.started":"2025-11-09T10:22:56.099540Z","shell.execute_reply":"2025-11-09T10:22:56.127634Z"}},"outputs":[{"name":"stdout","text":"Probability: 0.94, Label: positive ðŸ˜€\nProbability: 0.55, Label: positive ðŸ˜€\nProbability: 0.59, Label: positive ðŸ˜€\nProbability: 0.21, Label: negative ðŸ˜ž\nProbability: 0.43, Label: negative ðŸ˜ž\n","output_type":"stream"}],"execution_count":305},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}